{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snrism/sdxl-tuner/blob/main/Fine_tune_Images_SDXL_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SDXL Fine-tuning\n",
        "\n",
        "Stability AI open-sourced [SDXL](https://replicate.com/blog/run-sdxl-with-an-api), that allows you to fine tune diffusion models to learn patterns in input images.\n",
        "\n",
        "In this colab, you can use [Replicate](https://replicate.com) via [running from the web](https://replicate.com/stability-ai/sdxl) or using the [API](https://replicate.com/blog/run-sdxl-with-an-api) to tune a model."
      ],
      "metadata": {
        "id": "51L4ynq8qPLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install replicate\n",
        "import os\n",
        "import replicate\n",
        "from google.colab import output\n",
        "output.clear()"
      ],
      "metadata": {
        "id": "gLWKQvpeqAHE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Authenticate by setting your token in an environment variable:"
      ],
      "metadata": {
        "id": "iVf3RWPKqKeb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get your token from https://replicate.com/account\n",
        "from getpass import getpass\n",
        "\n",
        "REPLICATE_API_TOKEN = getpass()\n",
        "os.environ[\"REPLICATE_API_TOKEN\"] = REPLICATE_API_TOKEN"
      ],
      "metadata": {
        "id": "NuZ8DpPcqJ0w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "680a9666-d761-4a9a-817a-b24a80d5ea61"
      },
      "execution_count": 23,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare your training images\n",
        "\n",
        "- Images can be of yourself or a particular style like illustrations. - Images can be in JPEG or PNG format.\n",
        "- Dimensions and size don't matter.\n",
        "- Filenames don't matter.\n",
        "\n",
        "Zip your images.\n",
        "\n",
        "```console\n",
        "zip -r data.zip data\n",
        "```\n",
        "\n",
        "Upload this file somewhere on the internet that is publicly accessible, like an GCS bucket, S3 bucket or a GitHub Pages site."
      ],
      "metadata": {
        "id": "mNepKK_OquqM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Create a model\n",
        "\n",
        "Create a model by reusing the owner name below. Set the model name and feel free to reuse the devault visibility and hardware values.\n",
        "\n",
        "You can also create a model via [replicate.com/create](https://replicate.com/create)."
      ],
      "metadata": {
        "id": "A7MAt8gZq4h1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import replicate\n",
        "\n",
        "client = replicate.Client(api_token=REPLICATE_API_TOKEN)\n",
        "client.models.create(\n",
        "    owner=\"snrism\",\n",
        "    name=\"YOUR_MODEL_NAME\",\n",
        "    visibility=\"private\",\n",
        "    hardware=\"gpu-a40-large\"\n",
        ")"
      ],
      "metadata": {
        "id": "DIN9aOdK7EYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the following to get the model object to retrieve the latest version of the model.\n",
        "\n",
        "Look for the version attribute which is required to create a new training instance below."
      ],
      "metadata": {
        "id": "KE7vhvf0YsG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = client.models.get(\"stability-ai/sdxl\")\n",
        "print(model)"
      ],
      "metadata": {
        "id": "n8T3Q7VB7ONn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start the training"
      ],
      "metadata": {
        "id": "jr8j63kFqijO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: Below is an example of using SDXL model from Stability AI. It does a pretty good job of capturing style and reflecting that in the output.\n",
        "# Recently, FLUX from BlackForest Labs (https://blackforestlabs.ai/) created a better image genreation model that produced high quality images. Give it a shot by replacing the version below\n",
        "# with FLUX's model version=\"ostris/flux-dev-lora-trainer:885394e6a31c6f349dd4f9e6e7ffbabd8d9840ab2559ab78aed6b2451ab2cfef\",\n",
        "# input={\n",
        "#   \"steps\": 1000,\n",
        "#    \"lora_rank\": 16, -> More adaptable model, but higher memory and computation requirements. It can capture more complex nuances in your data but risks overfitting if set too high.\n",
        "#    \"optimizer\": \"adamw8bit\",\n",
        "#    \"batch_size\": 1,\n",
        "#    \"resolution\": \"512,768,1024\",\n",
        "#    \"autocaption\": True,\n",
        "#    \"input_images\": \"https://\",\n",
        "#    \"trigger_word\": \"TOK\",\n",
        "#    \"learning_rate\": 0.0004,\n",
        "#    \"wandb_project\": \"flux_train_replicate\",\n",
        "#    \"wandb_save_interval\": 100,\n",
        "#    \"caption_dropout_rate\": 0.05,\n",
        "#    \"cache_latents_to_disk\": False,\n",
        "#    \"wandb_sample_interval\": 100\n",
        "#  },\n",
        "###\n",
        "\n",
        "training = client.trainings.create(\n",
        "    version=\"stability-ai/sdxl:c221b2b8ef527988fb59bf24a8b97c4561f1c671f73bd389f866bfb27c061316\",\n",
        "    input={\n",
        "        \"input_images\": \"YOUR_ZIP_FILE\",\n",
        "        \"caption_prefix\": \"UNIQUE CAPTION USED IN YOUR PROMPT. YOU CAN REMOVE IT\",\n",
        "        \"token_string\": \"UNIQUE IDENTIFIER TO REFER TO YOUR IMAGES. e.g., a photo of TOK\",\n",
        "        \"use_face_detection_instead\": False,\n",
        "        \"is_lora\": True,\n",
        "    },\n",
        "    destination=\"snrism/YOUR_MODEL_NAME\"\n",
        ")"
      ],
      "metadata": {
        "id": "0AefVmqxLIjY"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Monitor training progress\n",
        "\n",
        "To follow the progress of the training job, run the following code to track the training status."
      ],
      "metadata": {
        "id": "HGiaTo2frZ8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Continuously reload the training object and check the status\n",
        "while True:\n",
        "    # Reload the training status\n",
        "    training.reload()\n",
        "\n",
        "    # Print the current status\n",
        "    print(f\"Status: {training.status}\")\n",
        "\n",
        "    # Check if the status is 'processing'\n",
        "    if training.status == 'processing':\n",
        "        # Show the last 10 lines of logs\n",
        "        print(\"\\n\".join(training.logs.split(\"\\n\")[-10:]))\n",
        "\n",
        "    elif training.status == 'succeeded':\n",
        "        # Print final logs when succeeded and break the loop\n",
        "        print(\"\\nTraining succeeded! Here are the final logs:\")\n",
        "        break\n",
        "\n",
        "    elif training.status == 'failed':\n",
        "        # If training failed, print the error message and break the loop\n",
        "        print(\"Training failed. Here are the logs:\")\n",
        "        print(\"\\n\".join(training.logs.split(\"\\n\")))\n",
        "        break\n",
        "\n",
        "    # Wait for a few seconds before rechecking (you can adjust the interval)\n",
        "    time.sleep(2)"
      ],
      "metadata": {
        "id": "YkRQwY-AtNu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the model\n",
        "\n",
        "When the model has finished training you can run it using the GUI on replicate.com/my-name/my-model, or via the API:\n"
      ],
      "metadata": {
        "id": "5kk3zlqkrl8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = client.run(\n",
        "    training.output[\"version\"],\n",
        "    input={\"prompt\": \"kids playing in the park with pinata\"},\n",
        ")\n",
        "print(output)"
      ],
      "metadata": {
        "id": "D5RVsCNPro1X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}